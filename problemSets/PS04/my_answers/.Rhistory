language_frequency <- as.data.frame(table(kaggle2022_Q12_long$Used))
language_frequency
#Find the language frequency, as a data frame
language_frequency_df <- as.data.frame(table(kaggle2022_Q12_long$Used))
#Remove the column headers
lang_freq_df <- language_frequency_df[-c(1), ]
#Remove the column headers
lang_freq_df <- language_frequency_df[-c(1), ]
#Find the proportions of programming languages used
prop.table(lang_freq_df)*100
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = -RespondentID,
names_to = "Question", values_to = "Used") %>%
filter(!is.na(Used))  # Remove rows where "Used" is NA
#Assign ID number to each respondent
kaggle2022_Q12 <- seq_along(kaggle2022_Q12$Q12)
#Import Kaggle 2022 data set
PATH <- "/Users/clarezureich/Documents/Applied Social Data Science/Computer Programming/kaggle_survey_2022_responses.csv"
questions <- readr::read_csv(PATH, n_max = 1)
kaggle2022 <- readr::read_csv(PATH, col_names = names(questions), skip = 2)
#Load tidy and dplyr packages
library(dplyr)
library(tidyr)
#Evaluate the entire Kaggle data frame
head(kaggle2022, 1)
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
select(31:45)
View(kaggle2022_Q12)
View(kaggle2022_Q12)
#Find the number of rows in data frame
total <- nrow(kaggle2022_Q12$31:45)
#Assign ID number to each respondent
kaggle2022_Q12 <- seq_along(kaggle2022_Q12$31:45)
#Assign ID number to each respondent
kaggle2022_Q12 <- seq_along(kaggle2022_Q12[, 31:45])
#Assign ID number to each respondent
kaggle2022_Q12 <- seq_along(kaggle2022_Q12[, 1:15])
kaggle2022_Q12
#Remove the column headers
lang_freq_df <- language_frequency_df[-c(1), ]
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
select(31:45)
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
starts_with("Q12")
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
starts_with('Q12')
#Evaluate the entire Kaggle data frame
head(kaggle2022, 1)
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
starts_with('Q12')
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
select(starts_with("Q12"))
kaggle2022_Q12
#Assign ID number to each respondent
kaggle2022_Q12 <- cbind(Respondent_ID = 1:nrow(kaggle2022_Q12),
kaggle2022_Q12)
kaggle2022_Q12
View(kaggle2022_Q12)
View(kaggle2022_Q12)
View(kaggle2022_Q12)
View(kaggle2022_Q12)
View(kaggle2022_Q12)
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = -RespondentID,
names_to = "Language", values_to = "Used") %>%
filter(!is.na(Used))  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = -RespondentID,
names_to = "Language", values_to = "Used") %>%
filter(!is.na(Used))  # Remove rows where "Used" is NA/blank
#Assign ID number to each respondent
kaggle2022_Q12 <- cbind(Respondent_ID = 1:nrow(kaggle2022_Q12),
kaggle2022_Q12)
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = -Respondent_ID,
names_to = "Language", values_to = "Used") %>%
filter(!is.na(Used))  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = Respondent_ID,
names_to = "Language", values_to = "Used") %>%
filter(!is.na(Used))  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = everything(),
names_to = "Language", values_to = "Used") %>%
filter(!is.na(Used))  # Remove rows where "Used" is NA/blank
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = everything(),
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
select(starts_with("Q12"))
#Find the number of rows in data frame
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = everything(),
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Assign ID number to each respondent
kaggle2022_Q12 <- cbind(Respondent_ID = 1:nrow(kaggle2022_Q12),
kaggle2022_Q12)
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = everything(),
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = Respondent_ID,
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Assign ID number to each respondent
kaggle2022_Q12 <- cbind(Respondent_ID = 1:nrow(kaggle2022_Q12),
kaggle2022_Q12)
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = Respondent_ID,
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = -Respondent_ID,
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Find the number of rows in data frame
total <- nrow(kaggle2022_Q12)
#Assign ID number to each respondent
kaggle2022_Q12 <- cbind(Respondent_ID = 1:nrow(kaggle2022_Q12),
kaggle2022_Q12)
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = -Respondent_ID,
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Find the language frequency, as a data frame
language_frequency_df <- kaggle2022_Q12_long %>%
group_by(Used) %>%
#Remove the column headers
lang_freq_df <- language_frequency_df[-c(1), ]
#Find the language frequency, as a data frame
language_percentage <- kaggle2022_Q12_long %>%
group_by(Used) %>%
summarise(Count = n()) %>%
mutate(Percentage = Count /total * 100) %>%
arrange(desc(Percentage))
language_percentage
#Import Kaggle 2022 data set and remove first two rows of questions
PATH <- "/Users/clarezureich/Documents/Applied Social Data Science/Computer Programming/kaggle_survey_2022_responses.csv"
kaggle2022 <- readr::read_csv(PATH, col_names = names(questions), skip = 2)
#Load tidy and dplyr packages
library(dplyr)
library(tidyr)
#Read and load file
#Import Kaggle 2022 data set and remove first two rows of questions
PATH <- "/Users/clarezureich/Documents/Applied Social Data Science/Computer Programming/kaggle_survey_2022_responses.csv"
#Read and load file
#Import Kaggle 2022 data set and remove first two rows of questions
PATH <- "/Users/clarezureich/Documents/Applied Social Data Science/Computer Programming/kaggle_survey_2022_responses.csv"
questions <- readr::read_csv(PATH, n_max = 1)
kaggle2022 <- readr::read_csv(PATH, col_names = names(questions), skip = 2)
View(questions)
View(questions)
View(kaggle2022)
View(kaggle2022)
#Read and load file
#Import Kaggle 2022 data set and remove first two rows of questions
PATH <- "/Users/clarezureich/Documents/Applied Social Data Science/Computer Programming/kaggle_survey_2022_responses.csv"
questions <- readr::read_csv(PATH, n_max = 1)
kaggle2022 <- readr::read_csv(PATH, col_names = names(questions), skip = 2)
#Load tidy and dplyr packages
library(dplyr)
library(tidyr)
#Evaluate the entire Kaggle data frame
head(kaggle2022, 1)
#Subset Programming Questions (Question 12, part 1-15)
kaggle2022_Q12 <- kaggle2022 %>%
select(starts_with("Q12"))
#Find the number of rows in data frame
total <- nrow(kaggle2022_Q12)
#Assign ID number to each respondent
kaggle2022_Q12 <- cbind(Respondent_ID = 1:nrow(kaggle2022_Q12),
kaggle2022_Q12)
#Pivot long to gather columns in a variable pair
kaggle2022_Q12_long <- kaggle2022_Q12 %>%
pivot_longer(cols = -Respondent_ID,
names_to = "Language",
values_to = "Used") %>%
filter(!is.na(Used)  & Used != "")  # Remove rows where "Used" is NA/blank
kaggle2022_Q12_long
#Find the language frequency, as a data frame
language_percentage <- kaggle2022_Q12_long %>%
group_by(Used) %>%
summarise(Count = n()) %>%
mutate(Percentage = Count /total * 100) %>%
arrange(desc(Percentage))
language_percentage
# Your code goes here
View(kaggle2022)
View(kaggle2022)
View(kaggle2022_Q12)
View(kaggle2022_Q12)
responses <- PATH
#colnames(responses) #checking column names
question12 <- responses %>% select(starts_with("Q12")) #subsetting only Q12 questions
responses <- PATH
#colnames(responses) #checking column names
question12 <- responses %>% select(starts_with("Q12")) #subsetting only Q12 questions
responses <- PATH
#colnames(responses) #checking column names
question12 <- responses %>% select(starts_with("Q12")) #subsetting only Q12 questions
responses <- PATH
#colnames(responses) #checking column names
question12 <- responses %>% select(starts_with("Q12")) #subsetting only Q12 questions
responses <- PATH
#colnames(responses) #checking column names
question12 <- responses %>% select(starts_with("Q12")) #subsetting only Q12 questions
library(readr)
kaggle_survey_2022_responses <- read_csv("Documents/Applied Social Data Science/Computer Programming/kaggle_survey_2022_responses.csv")
View(kaggle_survey_2022_responses)
responses <- kaggle_survey_2022_responses
#colnames(responses) #checking column names
question12 <- responses %>% select(starts_with("Q12")) #subsetting only Q12 questions
question12 <- question12[-1, ] #remove the first row showing the question
#colnames(question12) #checking colnames to ensure first row removed
pivot12 <- question12 %>%
pivot_longer(cols = everything(),
names_to = "program",
values_to = "used") %>%
filter(!is.na(used) & used != "") #dropping rows with no responses (blanks)
language_count <- pivot12 %>%  #calculating program frequencies
group_by(used) %>%
summarise(count = n()) %>%
ungroup()
total <- nrow(language_count)
language_count$percentage <- (language_count$count/total)*100 #calculating percentages
colnames(language_count) <- c("language", "count", "percentage") #formatting
high_to_low_languages <- language_count %>% arrange(desc(percentage)) #arranging by popularity
high_to_low_languages
responses <- kaggle_survey_2022_responses
#colnames(responses) #checking column names
question12 <- responses %>% select(starts_with("Q12")) #subsetting only Q12 questions
question12 <- question12[-1, ] #remove the first row showing the question
#colnames(question12) #checking colnames to ensure first row removed
pivot12 <- question12 %>%
pivot_longer(cols = everything(),
names_to = "program",
values_to = "used") %>%
filter(!is.na(used) & used != "") #dropping rows with no responses (blanks)
language_count <- pivot12 %>%  #calculating program frequencies
group_by(used) %>%
summarise(count = n()) %>%
ungroup()
total <- nrow(question12)
language_count$percentage <- (language_count$count/total)*100 #calculating percentages
colnames(language_count) <- c("language", "count", "percentage") #formatting
high_to_low_languages <- language_count %>% arrange(desc(percentage)) #arranging by popularity
high_to_low_languages
language_percentage
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# read in data
inc.sub <- read.csv("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2024/main/datasets/incumbents_subset.csv")
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# read in data
inc.sub <- read.csv("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2024/main/datasets/incumbents_subset.csv")
getd()
getwd()
# read in data
install.packages(car)
getwd()
# read in data
install.packages(car)
library(car)
data(Prestige)
help(Prestige)
# read in data
install.packages(car); library(car)
# read in data
install.packages(car); library(car)
data(Prestige); help(Prestige)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c("ggplot2", "stargazer"),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# read in data
install.packages(car); library(car)
# read in data
install.packages("car")
library("car")
data(Prestige)
help(Prestige)
getwd()
View(Prestige)
View(Prestige)
Prestigue$professional <- as.factor(ifelse(Prestige$type=="prof", 1,
ifelse(Prestige$type=="bc" | Prestige$type=="wc", 0, NA)))
head(professional)
Prestige$professional <- as.factor(ifelse(Prestige$type=="prof", 1,
ifelse(Prestige$type=="bc" | Prestige$type=="wc", 0, NA)))
head(professional)
head(professional)
Prestige$professional <- as.factor(ifelse(Prestige$type=="prof", 1,
ifelse(Prestige$type=="bc" | Prestige$type=="wc", 0, NA)))
head(Prestige$professional)
levels(Prestige$professional)
levels(Prestige$professional)
summary(Prestige$professional)
levels(Prestige$professional); summary(Prestige$professional)
#Part B
prestige_regression <- ln(prestige ~ income + professional + income x professional, data = Prestige)
#Part B
prestige_regression <- ln(prestige ~ income + professional + income * professional, data = Prestige)
#Part B
q1b_reg <- lm(prestige ~ income + professional + income * professional,
data = Prestige)
#Part B
prestige_regression <- lm(prestige ~ income + professional + income * professional,
data = Prestige)
prestige_regression2 <- lm(prestige ~ income * professional,
data = Prestige)
prestigue_regression
prestige_regression
prestige_regression2
#Part F
#prestige = 21.1422 + .003*income + 37.781*professional -. 002(income*professional)
income_change <- 21.1422 + .003*1000 + 37.781*1 - (.002*1000*1)
income_change
income_change2 <- 21.1422 + .003*0 + 37.781*1 - (.002*0*1)
income_change2
income_change2 <- 21.1422 + 37.781
income_change2
income_change2 <- 21.1422 + (.003*0) + (37.781*1) - (.002*1000*1)
income_change2
income_change2 <- 21.1422 + (.003*0) + (37.781*1) - (.002*0*1)
income_change2
prestige_change = income_change2-income_change
prestige_change
prestige_change = income_change-income_change2
prestige_change
#Part G
professional_change <- 21.1422 + (.003*6000) + (37.781*0) - (.002*6000*0)
professional_change
professional_change2 <- 21.1422 + (.003*6000) + (37.781*1) - (.002*6000*1)
professional_change2
#Part G
professional_change <- 21.1422 + (.003*6000) + (37.781*1) - (.002*6000*1)
professional_change
professional_change2 <- 21.1422 + (.003*6000) + (37.781*0) - (.002*6000*0)
professional_change2
prestige_change2 <- professional_change - professional_change2
prestige_change2
print("Prestigue increases by", prestige_change2)
print('Prestigue increases by', prestige_change2)
#Part F
#prestige = 21.1422 + .003*income + 37.781*professional -. 002(income*professional)
income_change <- 21.1422 + (.003*1000) + (37.781*1) - (.002*1000*1)
income_change
income_change2 <- 21.1422 + (.003*0) + (37.781*1) - (.002*0*1)
income_change2
t-stat <- .042/.016
t-stat
t_stat <- .042/.016
t_stat
#Find the p-value
df <- 131-2-1
df
p_value <- 2*pt(2.625, df, lower.tail = FALSE)
p_value
p_value <- 2*pt(t_stat, df, lower.tail = FALSE)
p_value
#Part B
t_stat_adjacent <- .042/.013
t_stat_adjacent
p_value <- 2*pt(t_stat_adjacent, df, lower.tail = FALSE)
p_value <- 2*pt(t_stat, df, lower.tail = FALSE)
p_value
p_value_adjacent <- 2*pt(t_stat_adjacent, df, lower.tail = FALSE)
p_value_adjacent
#Part C
#The baseline group, a district with no assigned lawn signs and not adjacent to a lawn sign precinct, is expected to have
#a vote share of .302 per Cuccinelli.
t_stat_constant <- .302/.011
t_stat_constant
30+76
#Part B
prestige_regression <- lm(prestige ~ income + professional + income * professional, data = Prestige)
prestige_regression
summary(prestige_regression)
#Part F
#Prediction equation: prestige = 21.1422 + .003*income + 37.781*professional -. 002(income*professional)
income_change <- 21.1422 + (.003*1000) + (37.781*1) - (.002*1000*1)
income_change
income_change2 <- 21.1422 + (.003*0) + (37.781*1) - (.002*0*1)
income_change2
#Part F
#Prediction equation: prestige = 21.1422 + .003*income + 37.781*professional -. 002(income*professional)
income_change <- 21.1422 + (.003*1000) + (37.781*1) - (.002*1000*1)
income_change
income_change2 <- 21.1422 + (.003*0) + (37.781*1) - (.002*0*1)
income_change2
prestige_change = income_change-income_change2
prestige_change
#Part G
professional_change <- 21.1422 + (.003*6000) + (37.781*1) - (.002*6000*1)
professional_change
professional_change2 <- 21.1422 + (.003*6000) + (37.781*0) - (.002*6000*0)
professional_change2
prestige_change2 <- professional_change - professional_change2
prestige_change2
#Find the test statistic
t_stat <- .042/.016
t_stat
#Find the test statistic
t_stat <- .042/.016
t_stat
#Find the p-value
df <- 131-2-1
p_value <- 2*pt(t_stat, df, lower.tail = FALSE)
p_value
#Part B
t_stat_adjacent <- .042/.013
t_stat_adjacent
p_value_adjacent <- 2*pt(t_stat_adjacent, df, lower.tail = FALSE)
p_value_adjacent
#Part C
#The baseline group, a district with no assigned lawn signs and not adjacent to a lawn sign precinct, is expected to have
#a vote share of .302 per Cuccinelli. The t-stat for the constant is 27.45, which is large compared to the
#test statistics calculated for the precinct assigned lawn signs and precinct adjacent to lawn signs coefficients.
t_stat_constant <- .302/.011
t_stat_constant
